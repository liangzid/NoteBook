---
title: 2019-12-23-log 
tags: AlgorithmLearning, WorkLog
renderNumberedHeading: true
grammar_cjkRuby: true
---

今日开始阅读GNN方向相关论文,主要是针对那一篇a comprehensive survey on graph neural networks.
阅读笔记记录在了[这里]().

今天晚上开了实验的会,主要是和王老师讨论有关于最近画图的问题.我和张学长很显然做的很差.
分析了一下原因,我认为主要问题在于:
1. 和老师讨论不应该直接给老师看图,毫无意义.
2. 在实验部分应该这样设计:针对某某问题(比如task2的similarity search),某某特征很有研究的必要性(比如search的"准"和"快"),如果我们的算法是针对这里面的某个特性进行的设计(比如fastMaxlog的特性是"fast"),那么在进行实验设计时就应该包含该特性的实验图表.
3. 在给出一张图的前后一定要有陈述逻辑,这种陈述逻辑也可以理解为是书写论文时的行文逻辑.比如说,在算法性能表现最佳的某个场景下,执行similarity search任务,那么实验的数据集就必须得契合这个场景.然后给出:为什么我的结果这么好?为什么别人的结果那么那么差?一定要说明白,不然别人就会以为自己的编数据.
4. 接上一条.同样的问题是:不能让别人的算法太差.比如OPH,precision接近0recall接近1这是难以接受的,虽然可以说得通,但是这个baseline在此处就不适合放上去,就是因为太离谱.如果硬要放,可以,但是需要有一个"过渡"的逻辑.比如说:先给出一个正常的数据集上的precision和recall,展现我们算法不俗的性能,然后行文上给出一个实际常见的应用场景,在这个常见但是"特殊"的场景下说明OPH不可行的原因,然后给出一张OPH不行的图.这样是审稿人可以接受的.必要字眼可以在论文中加黑加粗.王老师说可以用很多数据集,我觉得这可能是气话,选取有代表性的就好了.
5. 一定要找准让图美观的点,我觉得这个b和c选取的不合适.我觉得b-c只要取一处值就可以了,因为这是LSH算法的层面,不是我们的算法想要展示的东西,相似度可以多选.
6. similarity search里面时间的图还是很有放上去的必要的,不然怎么能体现我们的fast呢?但是这张图同样需要行文逻辑的支撑,王老师认为task2里时间消耗的图不应该和task1里差距太大,我觉得有道理.张学长站的角度是实际的结果,但是实验的结果必须要尽量满足实验设计的要求.既然我们的算法是fast,实验就要支持理论,且符合常识.我认为只要把生成sketch的时间和查询时间加在一起就可以解决这个问题了,毕竟针对流数据存储sketch也是意义不大.这样task2的就会和task1很相似了.至于OPH可能会稍微快一点,在学长选的那个wiki数据集上不存在的,这样只要说明清楚理由,为什么咱们的算法的适用性就更容易得到提升了.

下面是针对王老师的一些问题的个人思考.张学长肯定会思考这个问题的,我到时候只需要认真倾听就好了.此处就写下自己的思考吧!

为什么OPH的precision是0, recall是1?
因为OPH search到的集合非常多,虽然囊括了所有的真实集合,但是也有更多的虚假集合.那么,接下来的问题是:为什么OPH会找错这么多?因为OPH只进行1次hash,而如果集合i里面元素的个数n_i远远小于k,那么大多数OPH生成的sketch就是空的,也就是初始值.所以OPH觉得所有的集合都和他的query.

