---
title: 2019-12-9-log
tags: 日志
renderNumberedHeading: true
grammar_cjkRuby: true
---


# 12.09 

由于今天要讨论实验的设计,所以听张远鸣的看了[论文<Fast Generating A Large Number of Gumbel-Max Variables\>]()的实验部分,总结如下:
1. 实验要为task服务,
2. 三要素是:dataset,baseline,以及metric
3. 控制好变量多画一些图,一定要表现出自己的优势.

## 基于以上几点,我把自己对FastMaxlog的实验设计修改为:

1. 验证的task是:  similarity estimation and similarity search.
2. dataset选用: 除了自己生成的流式数据之外,应该再添加两个real-world dataset作为佐证
3. baseline选取:经典的MinHash(作为相似度估计的),MaxlogHash(作为时间复杂度估计的),maxlogOPH(作为相似度估计的)
4. metric选取:算法平均时间,RMSE,MSE

## 在以上东西的基础上,目前构思画下面几组图:
### 在similarity estimation验证算法efficiency
这组图画4个,
1. Xaxis: 选取sketch的大小k
2. Yaxis:average time
3. baseline:三个都跑,(或许可以去掉OPH???)
4. 第四个变量:数据集的大小n (但是我们的这个是针对流式数据的,所以这里或许有一定的不合理之处)
### 在similarity estimation验证针对流式数据的efficiency
这组图也画4个,每张图中
1. Xaxis: n的变化.流式数据,n逐渐增大,可以是等量,也可以是指数 量...?
2. Yaxis:average time
3. baseline:三个都跑,(或许可以去掉OPH???)

 第四个变量:k=2<<7,2<<8,2<<9,2<<10
### 在真实数据集上验证efficiency
还没有调研清楚,想选择现实场景中真实存在的流式数据相关的数据集,如日志文件/评论/等等东西.

similarity estimation常用数据集:realsim,RCV1,webspam,libimseti,Last.fm

每个选定的数据集画一张图,每张图中:
1. Xaxis: n的变化.流式数据,n逐渐增大,可以是等量,也可以是指数 量...?
2. Yaxis:average time
3. baseline:三个都跑,(或许可以去掉OPH???)
K取固定值256
### 验证流式数据的准确度
1. Xaxis: n的变化.流式数据,n逐渐增大,可以是等量,也可以是指数 量...?
2. Yaxis:RMSE
3. baseline:三个
这里的问题在于,随着n的增大,Similarity在不断的变化,因此真正的Jaccard相似度是硬算呢还是怎么?
这里的OPH可以使用两种Dens方法都比较一下
### 算法自身的实验
1. Xaxis: k in 2^(7,8,9,10)
2. Yaxis:average time
3. 曲线:对于最终n=bigNumber相同的情形,每次流入的数据的数据量为变量,画一张图
