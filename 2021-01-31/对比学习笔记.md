> name: liangzid mail:2273067585@qq.com
# 对比学习在NLP下的应用
最近几天看了一些和对比学习相关的论文，现整理如下：
## 基本概念
对比学习（contrastive learning）是被看作是一种自监督学习方法（SSL，Self-supervised Learning），本质上是为了在数据标签的设定下为数据学习到一个良好的表示。因此，对比学习本质上仍然可以看做是一种表示（representation）学习。
下表简单列举了各个领域比较经典的对比学习算法。

<colgroup><col></colgroup>
| Field | 备注 | Paper Name |
| CV | simCLR | A Simple Framework for Contrastive Learning of Visual Representations |
| CV | Moco, he kaiming | Improved Baselines with Momentum Contrastive Learning |
| CV |  | Supervised Contrastive Learning |
| Analysis |  | Intriguing Properties of Contrastive Losses |
| NLP | Hinton组 | DeCLUTR: Deep Contrastive Learning for Unsupervised Textual Representations |
| NLP | Liuzhiyuan组 | DeepChannel: Salience Estimation by Contrastive Learning for Extractive Document Summarization |
| NLP |  | CERT: Contrastive Self-supervised Learning for Language Understanding |	

其中，最著名的对比学习方法是simCLR和MOCO两类。现在将对二者进行